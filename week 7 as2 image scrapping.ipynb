{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce04b6cf-aef7-4e1c-9cc5-b25ecae90eed",
   "metadata": {},
   "source": [
    "**Go to this given URL and solve the following questions\n",
    "URL: https://www.youtube.com/@PW-Foundation/videos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd5cbd7-6b7d-44f3-a176-7e087ec0d252",
   "metadata": {},
   "source": [
    "**Q1. Write a python program to extract the video URL of the first five videos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99fde489-8cfb-45ca-9d86-d4d7b93171fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='video_urls.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f258afb1-70f7-4611-afbb-3e87e9948f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.youtube.com/@PW-Foundation/videos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b3ed47d-9215-462d-b761-5504bcd60409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "925ee979-b1a0-4a75-a266-9e2b48feb0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7dc90d87-e678-43d7-9294-bdd04061e98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e46b5cc-16cb-41a7-83c1-c0c33231a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = soup.find_all('a', {'id': 'thumbnail'}, href=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4fb8ffb-d145-42ba-85ee-07134eddb46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_urls = []\n",
    "for video in videos[0:5]:\n",
    "    video_urls.append(f\"https://www.youtube.com{video['href']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2365759e-a0b3-415f-93a0-4bc683ee4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, video_url in enumerate(video_urls, 1):\n",
    "    logging.info(f\"Video {idx} URL: {video_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce17ee14-0a1e-4fe5-9f61-f4722a07866e",
   "metadata": {},
   "source": [
    "**Q2. Write a python program to extract the URL of the video thumbnails of the first five videos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2930e09a-1bcd-4d9d-ba69-6866c803635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "thumbnail_urls = []\n",
    "for thumbnail in soup.find_all('img', {'id': 'img'}, limit=5):\n",
    "    thumbnail_url = thumbnail['src']\n",
    "    thumbnail_urls.append(thumbnail_url)\n",
    "for i, url in enumerate(thumbnail_urls, 1):\n",
    "    print(f\"Thumbnail {i}: {url}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd529c8-b91a-462f-a850-82add57c486d",
   "metadata": {},
   "source": [
    "**Q3. Extract the Title of the First Five Videos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "46bb9af2-b0bb-4662-832f-3cc0443e54c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "video_titles = []\n",
    "for video in soup.find_all('a', {'id': 'video-title'}, limit=5):\n",
    "    video_title = video['title']\n",
    "    video_titles.append(video_title)\n",
    "for i, title in enumerate(video_titles, 1):\n",
    "    print(f\"Video {i}: {title}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9d9335-a85f-4ebc-9bff-43aa1402dfe5",
   "metadata": {},
   "source": [
    "**Q4. Extract the Number of Views of the First Five Videos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2435bef1-ca47-471c-a3a9-85bb45af4fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "view_counts = []\n",
    "video_elements = soup.find_all('div', {'class': 'style-scope ytd-grid-video-renderer'}, limit=5)\n",
    "for video in video_elements:\n",
    "    view_count = video.find('span', {'class': 'style-scope ytd-grid-video-renderer'}).text.strip()\n",
    "    view_counts.append(view_count)\n",
    "for i, view in enumerate(view_counts, 1):\n",
    "    print(f\"Video {i} Views: {view}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2fdf7b-9e48-4f07-be99-e77f0b9129b8",
   "metadata": {},
   "source": [
    "**Q5. Extract the Time of Posting of Video for the First Five Videos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c623be7-2723-4af4-93fa-98d64ed806f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "posting_times = []\n",
    "video_elements = soup.find_all('div', {'class': 'style-scope ytd-grid-video-renderer'}, limit=5)\n",
    "for video in video_elements:\n",
    "    posting_time = video.find('div', {'id': 'metadata-line'}).find_all('span')[1].text.strip()\n",
    "    posting_times.append(posting_time)\n",
    "for i, time in enumerate(posting_times, 1):\n",
    "    print(f\"Video {i} Posted: {time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "33949847-4ebe-4c24-b9ec-5fad1d9dc707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to youtube_videos.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "video_urls = []\n",
    "thumbnail_urls = []\n",
    "video_titles = []\n",
    "view_counts = []\n",
    "posting_times = []\n",
    "video_elements = soup.find_all('div', {'class': 'style-scope ytd-grid-video-renderer'}, limit=5)\n",
    "for video in video_elements:\n",
    "    video_url = 'https://www.youtube.com' + video.find('a', {'id': 'video-title'})['href']\n",
    "    video_urls.append(video_url)\n",
    "\n",
    "    thumbnail_url = video.find('img', {'id': 'img'})['src']\n",
    "    thumbnail_urls.append(thumbnail_url)\n",
    "\n",
    "    video_title = video.find('a', {'id': 'video-title'})['title']\n",
    "    video_titles.append(video_title)\n",
    "\n",
    "    view_count = video.find('span', {'class': 'style-scope ytd-grid-video-renderer'}).text.strip()\n",
    "    view_counts.append(view_count)\n",
    "\n",
    "    posting_time = video.find('div', {'id': 'metadata-line'}).find_all('span')[1].text.strip()\n",
    "    posting_times.append(posting_time)\n",
    "data = {\n",
    "    'Video URL': video_urls,\n",
    "    'Thumbnail URL': thumbnail_urls,\n",
    "    'Title': video_titles,\n",
    "    'Views': view_counts,\n",
    "    'Posted': posting_times\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('youtube_videos.csv', index=False)\n",
    "\n",
    "print(\"Data saved to youtube_videos.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e9566282-a3ab-46ea-8904-ef0ec2c6cedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to youtube_videos.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "video_urls = []\n",
    "thumbnail_urls = []\n",
    "video_titles = []\n",
    "view_counts = []\n",
    "posting_times = []\n",
    "video_elements = soup.find_all('div', {'class': 'style-scope ytd-grid-video-renderer'}, limit=5)\n",
    "for video in video_elements:\n",
    "    video_url = 'https://www.youtube.com' + video.find('a', {'id': 'video-title'})['href']\n",
    "    video_urls.append(video_url)\n",
    "\n",
    "    thumbnail_url = video.find('img', {'id': 'img'})['src']\n",
    "    thumbnail_urls.append(thumbnail_url)\n",
    "\n",
    "    video_title = video.find('a', {'id': 'video-title'})['title']\n",
    "    video_titles.append(video_title)\n",
    "\n",
    "    view_count = video.find('span', {'class': 'style-scope ytd-grid-video-renderer'}).text.strip()\n",
    "    view_counts.append(view_count)\n",
    "\n",
    "    posting_time = video.find('div', {'id': 'metadata-line'}).find_all('span')[1].text.strip()\n",
    "    posting_times.append(posting_time)\n",
    "data = {\n",
    "    'Video URL': video_urls,\n",
    "    'Thumbnail URL': thumbnail_urls,\n",
    "    'Title': video_titles,\n",
    "    'Views': view_counts,\n",
    "    'Posted': posting_times\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('youtube_videos.csv', index=False)\n",
    "\n",
    "print(\"Data saved to youtube_videos.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2120026-1fd1-4965-978c-2b65d20049ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo apt update\n",
    "sudo apt install python3-pip\n",
    "pip3 install streamlit requests beautifulsoup4 pandas\n",
    "\n",
    "streamlit run app.py --server.port 80\n",
    "\n",
    "This project scrapes data from a YouTube channel's videos page and provides the following functionalities:\n",
    "- Extract video URLs\n",
    "- Extract video thumbnail URLs\n",
    "- Extract video titles\n",
    "- Extract video view counts\n",
    "- Extract video posting times\n",
    "- Save the data to a\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
